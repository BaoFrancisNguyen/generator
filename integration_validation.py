# integration_validation.py
"""
Module d'int√©gration pour connecter la validation automatique 
avec le g√©n√©rateur principal de donn√©es √©lectriques.

Ce module permet de :
1. Valider automatiquement chaque g√©n√©ration
2. Ajuster les param√®tres en temps r√©el
3. Sugg√©rer des am√©liorations
4. Maintenir un historique de qualit√©
"""

import json
import os
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
from pathlib import Path

# Import des modules cr√©√©s pr√©c√©demment
try:
    from quick_validation import QuickValidator
    from building_evaluation import BuildingEvaluator
    from building_distribution import BuildingDistributor
except ImportError as e:
    print(f"‚ö†Ô∏è Import manquant: {e}")
    print("Assurez-vous que tous les fichiers sont dans le m√™me dossier")

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('validation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class IntegratedValidator:
    """Syst√®me de validation int√©gr√© au g√©n√©rateur principal"""
    
    def __init__(self):
        self.quick_validator = QuickValidator()
        self.building_evaluator = BuildingEvaluator()
        self.building_distributor = BuildingDistributor()
        
        # Configuration des seuils de qualit√©
        self.quality_thresholds = {
            'excellent': 85,
            'good': 70,
            'acceptable': 55,
            'poor': 40
        }
        
        # Historique des validations
        self.validation_history_file = 'validation_history.json'
        self.validation_history = self._load_validation_history()
        
        # Compteurs pour l'auto-am√©lioration
        self.adjustment_counters = {}
        
    def _load_validation_history(self) -> List[Dict]:
        """Charge l'historique des validations"""
        if os.path.exists(self.validation_history_file):
            try:
                with open(self.validation_history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Erreur lors du chargement de l'historique: {e}")
        return []
    
    def _save_validation_history(self):
        """Sauvegarde l'historique des validations"""
        try:
            with open(self.validation_history_file, 'w', encoding='utf-8') as f:
                json.dump(self.validation_history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde de l'historique: {e}")
    
    def validate_generation(self, buildings_df: pd.DataFrame, 
                          timeseries_df: pd.DataFrame = None,
                          auto_adjust: bool = False) -> Dict:
        """
        Valide une g√©n√©ration compl√®te de donn√©es
        
        Args:
            buildings_df: DataFrame des b√¢timents g√©n√©r√©s
            timeseries_df: DataFrame des s√©ries temporelles (optionnel)
            auto_adjust: Si True, applique automatiquement les ajustements
            
        Returns:
            Dict avec r√©sultats de validation et recommandations
        """
        
        validation_session = {
            'timestamp': datetime.now().isoformat(),
            'total_buildings': len(buildings_df),
            'cities_analyzed': [],
            'overall_quality': {},
            'recommendations': [],
            'adjustments_applied': [],
            'data_quality_issues': []
        }
        
        logger.info(f"üîç D√©marrage validation - {len(buildings_df)} b√¢timents")
        
        # 1. Validation par ville
        city_validations = self._validate_by_city(buildings_df)
        validation_session['cities_analyzed'] = city_validations
        
        # 2. Validation des patterns de consommation (si disponible)
        if timeseries_df is not None:
            consumption_validation = self._validate_consumption_patterns(
                buildings_df, timeseries_df
            )
            validation_session['consumption_validation'] = consumption_validation
        
        # 3. Calcul de la qualit√© globale
        overall_quality = self._calculate_overall_quality(city_validations)
        validation_session['overall_quality'] = overall_quality
        
        # 4. G√©n√©ration des recommandations
        recommendations = self._generate_recommendations(city_validations, overall_quality)
        validation_session['recommendations'] = recommendations
        
        # 5. Auto-ajustement si demand√©
        if auto_adjust and overall_quality['score'] < self.quality_thresholds['good']:
            adjustments = self._apply_auto_adjustments(recommendations)
            validation_session['adjustments_applied'] = adjustments
        
        # 6. Sauvegarde dans l'historique
        self.validation_history.append(validation_session)
        self._save_validation_history()
        
        # 7. G√©n√©ration du rapport
        report = self._generate_integration_report(validation_session)
        validation_session['report'] = report
        
        logger.info(f"‚úÖ Validation termin√©e - Score: {overall_quality['score']}%")
        
        return validation_session
    
    def _validate_by_city(self, buildings_df: pd.DataFrame) -> List[Dict]:
        """Valide la distribution pour chaque ville"""
        
        city_validations = []
        
        # Grouper par ville
        for city in buildings_df['location'].unique():
            city_buildings = buildings_df[buildings_df['location'] == city]
            
            # Cr√©er la distribution pour cette ville
            city_distribution = city_buildings['building_class'].value_counts().to_dict()
            
            # Valider avec le quick validator
            validation_result = self.quick_validator.validate_city_distribution(
                city, city_distribution
            )
            
            # Ajouter des m√©tadonn√©es
            validation_result['buildings_count'] = len(city_buildings)
            validation_result['population'] = city_buildings.iloc[0]['population'] if len(city_buildings) > 0 else 0
            
            city_validations.append(validation_result)
            
            logger.info(f"üìç {city}: {validation_result['overall_score']}% - {validation_result['status']}")
        
        return city_validations
    
    def _validate_consumption_patterns(self, buildings_df: pd.DataFrame, 
                                     timeseries_df: pd.DataFrame) -> Dict:
        """Valide les patterns de consommation √©lectrique"""
        
        consumption_validation = {
            'total_observations': len(timeseries_df),
            'zero_consumption_rate': (timeseries_df['y'] == 0).sum() / len(timeseries_df),
            'consumption_ranges': {},
            'anomalies': [],
            'quality_score': 0
        }
        
        # Analyser par type de b√¢timent
        for building_type in buildings_df['building_class'].unique():
            building_ids = buildings_df[buildings_df['building_class'] == building_type]['unique_id']
            type_consumption = timeseries_df[timeseries_df['unique_id'].isin(building_ids)]['y']
            
            if len(type_consumption) > 0:
                consumption_validation['consumption_ranges'][building_type] = {
                    'min': float(type_consumption.min()),
                    'max': float(type_consumption.max()),
                    'mean': float(type_consumption.mean()),
                    'std': float(type_consumption.std())
                }
                
                # D√©tecter les anomalies
                if type_consumption.max() > type_consumption.mean() + 5 * type_consumption.std():
                    consumption_validation['anomalies'].append({
                        'type': building_type,
                        'issue': 'extreme_peak_consumption',
                        'max_value': float(type_consumption.max()),
                        'expected_max': float(type_consumption.mean() + 3 * type_consumption.std())
                    })
        
        # Score de qualit√© bas√© sur le r√©alisme
        quality_factors = []
        
        # Facteur 1: Taux de consommation nulle (doit √™tre < 5%)
        zero_rate = consumption_validation['zero_consumption_rate']
        if zero_rate < 0.005:
            quality_factors.append(100)
        elif zero_rate < 0.02:
            quality_factors.append(80)
        elif zero_rate < 0.05:
            quality_factors.append(60)
        else:
            quality_factors.append(30)
        
        # Facteur 2: Absence d'anomalies extr√™mes
        anomaly_penalty = min(50, len(consumption_validation['anomalies']) * 10)
        quality_factors.append(100 - anomaly_penalty)
        
        consumption_validation['quality_score'] = sum(quality_factors) / len(quality_factors)
        
        return consumption_validation
    
    def _calculate_overall_quality(self, city_validations: List[Dict]) -> Dict:
        """Calcule la qualit√© globale de la g√©n√©ration"""
        
        scores = [cv['overall_score'] for cv in city_validations if cv['overall_score'] > 0]
        
        if not scores:
            return {'score': 0, 'grade': 'UNVALIDATED', 'cities_validated': 0}
        
        overall_score = sum(scores) / len(scores)
        
        # D√©terminer le grade
        if overall_score >= self.quality_thresholds['excellent']:
            grade = 'EXCELLENT'
        elif overall_score >= self.quality_thresholds['good']:
            grade = 'GOOD'
        elif overall_score >= self.quality_thresholds['acceptable']:
            grade = 'ACCEPTABLE'
        else:
            grade = 'NEEDS_IMPROVEMENT'
        
        return {
            'score': round(overall_score, 1),
            'grade': grade,
            'cities_validated': len(scores),
            'best_city_score': max(scores),
            'worst_city_score': min(scores),
            'cities_above_threshold': len([s for s in scores if s >= self.quality_thresholds['good']])
        }
    
    def _generate_recommendations(self, city_validations: List[Dict], 
                                overall_quality: Dict) -> List[Dict]:
        """G√©n√®re des recommandations d'am√©lioration"""
        
        recommendations = []
        
        # Analyser les patterns d'erreurs
        common_issues = {}
        
        for city_validation in city_validations:
            for rec in city_validation.get('recommendations', []):
                issue_type = self._extract_issue_type(rec)
                if issue_type not in common_issues:
                    common_issues[issue_type] = {'count': 0, 'cities': [], 'examples': []}
                common_issues[issue_type]['count'] += 1
                common_issues[issue_type]['cities'].append(city_validation['city'])
                common_issues[issue_type]['examples'].append(rec)
        
        # Cr√©er des recommandations prioritaires
        for issue_type, issue_data in common_issues.items():
            if issue_data['count'] >= 2:  # Issue dans au moins 2 villes
                priority = 'HIGH' if issue_data['count'] >= len(city_validations) * 0.5 else 'MEDIUM'
                
                recommendations.append({
                    'type': 'SYSTEMATIC_ADJUSTMENT',
                    'priority': priority,
                    'issue': issue_type,
                    'affected_cities': issue_data['cities'],
                    'frequency': issue_data['count'],
                    'action': self._get_adjustment_action(issue_type),
                    'parameter_to_adjust': self._get_parameter_name(issue_type)
                })
        
        # Recommandations bas√©es sur la qualit√© globale
        if overall_quality['score'] < self.quality_thresholds['acceptable']:
            recommendations.append({
                'type': 'GENERAL_RECALIBRATION',
                'priority': 'HIGH',
                'action': 'Recalibrer compl√®tement le syst√®me avec plus de donn√©es r√©elles',
                'steps': [
                    'Collecter donn√©es officielles r√©centes',
                    'Ajuster tous les ratios de distribution',
                    'Tester sur √©chantillon r√©duit',
                    'Valider avant d√©ploiement complet'
                ]
            })
        
        return recommendations
    
    def _extract_issue_type(self, recommendation: str) -> str:
        """Extrait le type d'issue d'une recommandation"""
        if 'h√¥pital' in recommendation.lower() or 'hospital' in recommendation.lower():
            return 'hospital_distribution'
        elif '√©cole' in recommendation.lower() or 'school' in recommendation.lower():
            return 'school_distribution'
        elif 'h√¥tel' in recommendation.lower() or 'hotel' in recommendation.lower():
            return 'hotel_distribution'
        elif 'clinique' in recommendation.lower() or 'clinic' in recommendation.lower():
            return 'clinic_distribution'
        elif 'commercial' in recommendation.lower():
            return 'commercial_distribution'
        elif 'industriel' in recommendation.lower() or 'industrial' in recommendation.lower():
            return 'industrial_distribution'
        else:
            return 'other_distribution'
    
    def _get_adjustment_action(self, issue_type: str) -> str:
        """Retourne l'action d'ajustement pour un type d'issue"""
        actions = {
            'hospital_distribution': 'Ajuster le seuil de population minimale pour les h√¥pitaux',
            'school_distribution': 'Revoir le ratio √©coles/population selon les normes malaisiennes',
            'hotel_distribution': 'Diff√©rencier les ratios selon le type de ville (touristique/business)',
            'clinic_distribution': 'Ajuster la distribution des cliniques selon la densit√© urbaine',
            'commercial_distribution': 'Revoir la r√©partition commerciale selon l\'importance √©conomique',
            'industrial_distribution': 'Mieux cibler les zones industrielles r√©elles'
        }
        return actions.get(issue_type, 'Analyser et ajuster les param√®tres de distribution')
    
    def _get_parameter_name(self, issue_type: str) -> str:
        """Retourne le nom du param√®tre √† ajuster"""
        parameters = {
            'hospital_distribution': 'min_population_hospital',
            'school_distribution': 'schools_per_10k_ratio', 
            'hotel_distribution': 'hotel_ratio_by_city_type',
            'clinic_distribution': 'clinic_density_factor',
            'commercial_distribution': 'commercial_economic_factor',
            'industrial_distribution': 'industrial_hub_multiplier'
        }
        return parameters.get(issue_type, 'distribution_ratio')
    
    def _apply_auto_adjustments(self, recommendations: List[Dict]) -> List[Dict]:
        """Applique automatiquement les ajustements possibles"""
        
        adjustments_applied = []
        
        for rec in recommendations:
            if rec['type'] == 'SYSTEMATIC_ADJUSTMENT' and rec['priority'] == 'HIGH':
                adjustment = self._calculate_adjustment(rec)
                if adjustment:
                    adjustments_applied.append(adjustment)
                    logger.info(f"üîß Ajustement appliqu√©: {adjustment['description']}")
        
        return adjustments_applied
    
    def _calculate_adjustment(self, recommendation: Dict) -> Optional[Dict]:
        """Calcule l'ajustement num√©rique √† appliquer"""
        
        issue_type = recommendation['issue']
        
        # Exemple d'ajustements automatiques
        if issue_type == 'hospital_distribution':
            return {
                'parameter': 'min_population_hospital',
                'old_value': 80000,
                'new_value': 100000,
                'description': 'Augmentation seuil population pour h√¥pitaux',
                'justification': f"Erreur dans {recommendation['frequency']} villes"
            }
        elif issue_type == 'hotel_distribution':
            return {
                'parameter': 'hotel_ratio_tourist_areas',
                'old_value': 0.08,
                'new_value': 0.12,
                'description': 'Augmentation ratio h√¥tels zones touristiques',
                'justification': 'Sous-repr√©sentation dans destinations touristiques'
            }
        
        return None
    
    def _generate_integration_report(self, validation_session: Dict) -> str:
        """G√©n√®re un rapport d'int√©gration complet"""
        
        report = f"""
üîó RAPPORT D'INT√âGRATION - VALIDATION AUTOMATIQUE
{'='*65}

üìä R√âSUM√â DE LA G√âN√âRATION
{'-'*30}
Timestamp: {validation_session['timestamp']}
B√¢timents g√©n√©r√©s: {validation_session['total_buildings']:,}
Villes analys√©es: {len(validation_session['cities_analyzed'])}

üéØ QUALIT√â GLOBALE
{'-'*30}
Score: {validation_session['overall_quality']['score']}%
Grade: {validation_session['overall_quality']['grade']}
Villes valid√©es: {validation_session['overall_quality']['cities_validated']}
Villes >70%: {validation_session['overall_quality']['cities_above_threshold']}

üìç D√âTAIL PAR VILLE
{'-'*30}
"""
        
        for city in validation_session['cities_analyzed']:
            status_emoji = "‚úÖ" if city['overall_score'] >= 70 else "‚ö†Ô∏è" if city['overall_score'] >= 50 else "‚ùå"
            report += f"{status_emoji} {city['city']}: {city['overall_score']}% ({city.get('buildings_count', 0)} b√¢timents)\n"
        
        if validation_session['recommendations']:
            report += f"\nüí° RECOMMANDATIONS PRIORITAIRES\n{'-'*30}\n"
            for i, rec in enumerate(validation_session['recommendations'][:3], 1):
                report += f"{i}. [{rec['priority']}] {rec.get('action', 'Action non d√©finie')}\n"
        
        if validation_session.get('adjustments_applied'):
            report += f"\nüîß AJUSTEMENTS APPLIQU√âS\n{'-'*30}\n"
            for adj in validation_session['adjustments_applied']:
                report += f"‚Ä¢ {adj['description']}\n"
        
        # Tendance historique
        if len(self.validation_history) > 1:
            previous_score = self.validation_history[-2]['overall_quality']['score']
            current_score = validation_session['overall_quality']['score']
            trend = "üìà" if current_score > previous_score else "üìâ" if current_score < previous_score else "‚û°Ô∏è"
            
            report += f"\nüìà TENDANCE QUALIT√â\n{'-'*30}\n"
            report += f"√âvolution: {previous_score}% ‚Üí {current_score}% {trend}\n"
        
        report += f"\nüéØ PROCHAINES ACTIONS RECOMMAND√âES\n{'-'*30}\n"
        
        if validation_session['overall_quality']['score'] >= 80:
            report += "‚úÖ Qualit√© excellente - Continuer le monitoring\n"
            report += "üìä Consid√©rer l'ajout de nouvelles villes de r√©f√©rence\n"
        elif validation_session['overall_quality']['score'] >= 70:
            report += "üîß Ajustements mineurs recommand√©s\n"
            report += "üìã Valider sur davantage de villes\n"
        else:
            report += "‚ùó Recalibration n√©cessaire\n"
            report += "üìö Collecter plus de donn√©es de r√©f√©rence\n"
            report += "üîÑ Tester ajustements sur √©chantillon r√©duit\n"
        
        return report
    
    def get_quality_trend(self, days: int = 30) -> Dict:
        """Analyse la tendance qualit√© sur les derniers jours"""
        
        cutoff_date = datetime.now() - timedelta(days=days)
        
        recent_validations = [
            v for v in self.validation_history 
            if datetime.fromisoformat(v['timestamp']) >= cutoff_date
        ]
        
        if len(recent_validations) < 2:
            return {'status': 'insufficient_data', 'validations_count': len(recent_validations)}
        
        scores = [v['overall_quality']['score'] for v in recent_validations]
        
        return {
            'period_days': days,
            'validations_count': len(recent_validations),
            'average_score': sum(scores) / len(scores),
            'best_score': max(scores),
            'worst_score': min(scores),
            'trend': 'improving' if scores[-1] > scores[0] else 'declining' if scores[-1] < scores[0] else 'stable',
            'score_variance': max(scores) - min(scores)
        }
    
    def export_validation_metrics(self, filepath: str = 'validation_metrics.csv'):
        """Exporte les m√©triques de validation vers CSV pour analyse"""
        
        if not self.validation_history:
            logger.warning("Aucun historique de validation √† exporter")
            return
        
        metrics_data = []
        
        for validation in self.validation_history:
            base_metrics = {
                'timestamp': validation['timestamp'],
                'total_buildings': validation['total_buildings'],
                'overall_score': validation['overall_quality']['score'],
                'overall_grade': validation['overall_quality']['grade'],
                'cities_count': len(validation['cities_analyzed']),
                'recommendations_count': len(validation['recommendations'])
            }
            
            # Ajouter m√©triques par ville
            for city in validation['cities_analyzed']:
                city_metrics = base_metrics.copy()
                city_metrics.update({
                    'city_name': city['city'],
                    'city_score': city['overall_score'],
                    'city_status': city['status'],
                    'city_population': city.get('population', 0),
                    'city_buildings': city.get('buildings_count', 0)
                })
                metrics_data.append(city_metrics)
        
        df = pd.DataFrame(metrics_data)
        df.to_csv(filepath, index=False)
        
        logger.info(f"üìä M√©triques export√©es vers {filepath}")
        
        return df


# Fonction d'int√©gration avec le g√©n√©rateur principal
def integrate_with_main_generator():
    """
    Exemple d'int√©gration avec le g√©n√©rateur principal app.py
    √Ä ajouter dans les routes Flask
    """
    
    integration_code = '''
# √Ä ajouter dans app.py

from integration_validation import IntegratedValidator

# Instance globale du validateur
integrated_validator = IntegratedValidator()

@app.route('/generate', methods=['POST'])
def generate():
    try:
        # ... code existant de g√©n√©ration ...
        buildings_df = generator.generate_building_metadata(...)
        timeseries_df = generator.generate_timeseries_data(...)
        
        # NOUVELLE FONCTIONNALIT√â: Validation automatique
        validation_results = integrated_validator.validate_generation(
            buildings_df, 
            timeseries_df, 
            auto_adjust=True  # Ajustements automatiques
        )
        
        # Ajouter les r√©sultats de validation √† la r√©ponse
        return jsonify({
            'success': True,
            'buildings': buildings_df.to_dict('records'),
            'timeseries': timeseries_df.head(500).to_dict('records'),
            'stats': stats,
            'validation': {
                'quality_score': validation_results['overall_quality']['score'],
                'grade': validation_results['overall_quality']['grade'],
                'recommendations': validation_results['recommendations'][:3],
                'report': validation_results['report']
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/validation-history')
def get_validation_history():
    """Nouvelle API pour consulter l'historique de validation"""
    trend = integrated_validator.get_quality_trend(days=30)
    return jsonify({
        'success': True,
        'trend': trend,
        'recent_validations': integrated_validator.validation_history[-10:]
    })
    '''
    
    return integration_code


if __name__ == "__main__":
    # Test du syst√®me d'int√©gration
    print("üîó Test du syst√®me de validation int√©gr√©")
    
    # Cr√©er des donn√©es de test
    test_buildings = pd.DataFrame([
        {'unique_id': 'test1', 'location': 'Kuala Lumpur', 'building_class': 'Residential', 'population': 1800000},
        {'unique_id': 'test2', 'location': 'Kuala Lumpur', 'building_class': 'Hospital', 'population': 1800000},
        {'unique_id': 'test3', 'location': 'Langkawi', 'building_class': 'Hotel', 'population': 65000},
    ])
    
    test_timeseries = pd.DataFrame([
        {'unique_id': 'test1', 'timestamp': '2024-01-01 12:00', 'y': 5.5},
        {'unique_id': 'test2', 'timestamp': '2024-01-01 12:00', 'y': 45.2},
        {'unique_id': 'test3', 'timestamp': '2024-01-01 12:00', 'y': 12.8},
    ])
    
    # Tester la validation int√©gr√©e
    validator = IntegratedValidator()
    results = validator.validate_generation(test_buildings, test_timeseries, auto_adjust=True)
    
    print("‚úÖ Test termin√©!")
    print(f"Score de qualit√©: {results['overall_quality']['score']}%")
    print("\n" + results['report'])